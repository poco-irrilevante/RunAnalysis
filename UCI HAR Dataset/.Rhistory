## mean; either "sulfate" or "nitrate".
## 'id' is an integer vector indicating the monitor ID numbers
## to be used
## Return the mean of the pollutant across all monitors list
## in the 'id' vector (ignoring NA values)
# find all files in directoy, subsetted by id
file_list <- list.files(directory, full.names=TRUE)[id ]
for (file in file_list){
# if the merged dataset doesn't exist, create it
if (!exists("dataset")){
dataset <- read.csv(file)
}
# if the merged dataset does exist, append to it
if (exists("dataset")){
temp_dataset <- read.csv(file)
dataset<-rbind(dataset, temp_dataset)
rm(temp_dataset)
}
}
dataset
## check which column to use for average, ignoring NA
#if (pollutant == "sulfate") {
#  avg <- mean(dataset$sulfate, na.rm=TRUE)
#}
#else {
#  avg <- mean(dataset$nitrate, na.rm=TRUE)
#}
#avg
}
colnames(pollutantmean("~/Courses/R-Programming/Data/specdata", "sulfate", 1))
colnames(pollutantmean("~/Courses/R-Programming/Data/specdata", "sulfate", 1:2))
colnames(pollutantmean("~/Courses/R-Programming/Data/specdata", "sulfate", 1:3))
pollutantmean <- function(directory, pollutant, id = 1:332) {
## 'directory' is a character vector of length 1 indicating
## the location of the CSV files
## 'pollutant' is a character vector of length 1 indicating
## the name of the pollutant for which we will calculate the
## mean; either "sulfate" or "nitrate".
## 'id' is an integer vector indicating the monitor ID numbers
## to be used
## Return the mean of the pollutant across all monitors list
## in the 'id' vector (ignoring NA values)
# find all files in directoy, subsetted by id
file_list <- list.files(directory, full.names=TRUE)[id ]
for (file in file_list){
# if the merged dataset doesn't exist, create it
if (!exists("dataset")){
dataset <- read.csv(file)
}
# if the merged dataset does exist, append to it
if (exists("dataset")){
temp_dataset <- read.csv(file)
dataset<-rbind(dataset, temp_dataset)
rm(temp_dataset)
}
}
## check which column to use for average, ignoring NA
if (pollutant == "sulfate") {
avg <- mean(dataset$sulfate, na.rm=TRUE)
}
else {
avg <- mean(dataset$nitrate, na.rm=TRUE)
}
avg
}
pollutantmean("~/Courses/R-Programming/Data/specdata", "sulfate", 1:10)
pollutantmean <- function(directory, pollutant, id = 1:332) {
## 'directory' is a character vector of length 1 indicating
## the location of the CSV files
## 'pollutant' is a character vector of length 1 indicating
## the name of the pollutant for which we will calculate the
## mean; either "sulfate" or "nitrate".
## 'id' is an integer vector indicating the monitor ID numbers
## to be used
## Return the mean of the pollutant across all monitors list
## in the 'id' vector (ignoring NA values)
# find all files in directoy, subsetted by id
file_list <- list.files(directory, full.names=TRUE)[id ]
for (file in file_list){
# if the merged dataset doesn't exist, create it
if (!exists("dataset")){
dataset <- read.csv(file)
}
# if the merged dataset does exist, append to it
if (exists("dataset")){
temp_dataset <- read.csv(file)
dataset<-rbind(dataset, temp_dataset)
rm(temp_dataset)
}
}
## check which column to use for average, ignoring NA
if (pollutant == "sulfate") {
avg <- mean(dataset$sulfate, na.rm=TRUE)
}
else {
avg <- mean(dataset$nitrate, na.rm=TRUE)
}
round(avg,4)
}
pollutantmean("~/Courses/R-Programming/Data/specdata", "sulfate", 1:10)
pollutantmean("~/Courses/R-Programming/Data/specdata", "nitrate", 70:72)
pollutantmean("~/Courses/R-Programming/Data/specdata", "nitrate", 23)
pollutantmean <- function(directory, pollutant, id = 1:332) {
## 'directory' is a character vector of length 1 indicating
## the location of the CSV files
## 'pollutant' is a character vector of length 1 indicating
## the name of the pollutant for which we will calculate the
## mean; either "sulfate" or "nitrate".
## 'id' is an integer vector indicating the monitor ID numbers
## to be used
## Return the mean of the pollutant across all monitors list
## in the 'id' vector (ignoring NA values)
# find all files in directoy, subsetted by id
file_list <- list.files(directory, full.names=TRUE)[id ]
for (file in file_list){
# if the merged dataset doesn't exist, create it
if (!exists("dataset")){
dataset <- read.csv(file)
}
# if the merged dataset does exist, append to it
if (exists("dataset")){
temp_dataset <- read.csv(file)
dataset<-rbind(dataset, temp_dataset)
rm(temp_dataset)
}
}
## check which column to use for average, ignoring NA
if (pollutant == "sulfate") {
avg <- mean(dataset$sulfate, na.rm=TRUE)
}
else {
avg <- mean(dataset$nitrate, na.rm=TRUE)
}
round(avg,3)
}
pollutantmean("~/Courses/R-Programming/Data/specdata", "nitrate", 23)
pollutantmean("~/Courses/R-Programming/Data/specdata", "nitrate", 70:72)
pollutantmean <- function(directory, pollutant, id = 1:332) {
## 'directory' is a character vector of length 1 indicating
## the location of the CSV files
## 'pollutant' is a character vector of length 1 indicating
## the name of the pollutant for which we will calculate the
## mean; either "sulfate" or "nitrate".
## 'id' is an integer vector indicating the monitor ID numbers
## to be used
## Return the mean of the pollutant across all monitors list
## in the 'id' vector (ignoring NA values)
# find all files in directoy, subsetted by id
file_list <- list.files(directory, full.names=TRUE)[id ]
for (file in file_list){
# if the merged dataset doesn't exist, create it
if (!exists("dataset")){
dataset <- read.csv(file)
}
# if the merged dataset does exist, append to it
if (exists("dataset")){
temp_dataset <- read.csv(file)
dataset<-rbind(dataset, temp_dataset)
rm(temp_dataset)
}
}
## check which column to use for average, ignoring NA
if (pollutant == "sulfate") {
avg <- mean(dataset$sulfate)
}
else {
avg <- mean(dataset$nitrate)
}
round(avg,3)
}
pollutantmean("~/Courses/R-Programming/Data/specdata", "nitrate", 70:72)
pollutantmean <- function(directory, pollutant, id = 1:332) {
## 'directory' is a character vector of length 1 indicating
## the location of the CSV files
## 'pollutant' is a character vector of length 1 indicating
## the name of the pollutant for which we will calculate the
## mean; either "sulfate" or "nitrate".
## 'id' is an integer vector indicating the monitor ID numbers
## to be used
## Return the mean of the pollutant across all monitors list
## in the 'id' vector (ignoring NA values)
# find all files in directoy, subsetted by id
file_list <- list.files(directory, full.names=TRUE)[id ]
for (file in file_list){
# if the merged dataset doesn't exist, create it
if (!exists("dataset")){
dataset <- read.csv(file)
}
# if the merged dataset does exist, append to it
if (exists("dataset")){
temp_dataset <- read.csv(file)
dataset<-rbind(dataset, temp_dataset)
rm(temp_dataset)
}
}
## check which column to use for average, ignoring NA
if (pollutant == "sulfate") {
avg <- mean(dataset$sulfate, na.rm=TRUE)
}
else {
avg <- mean(dataset$nitrate, na.rm=TRUE)
}
round(avg,3)
}
pollutantmean("~/Courses/R-Programming/Data/specdata", "sulfate", 1:10)
pollutantmean("~/Courses/R-Programming/Data/specdata", "nitrate", 70:72)
pollutantmean <- function(directory, pollutant, id = 1:332) {
## 'directory' is a character vector of length 1 indicating
## the location of the CSV files
## 'pollutant' is a character vector of length 1 indicating
## the name of the pollutant for which we will calculate the
## mean; either "sulfate" or "nitrate".
## 'id' is an integer vector indicating the monitor ID numbers
## to be used
## Return the mean of the pollutant across all monitors list
## in the 'id' vector (ignoring NA values)
# find all files in directoy, subsetted by id
file_list <- list.files(directory, full.names=TRUE)[id ]
dataset = lapply(file_list, function(x){read.csv(file=x,header=T)})
Reduce(function(x,y) {merge(x,y)}, dataset)
## check which column to use for average, ignoring NA
if (pollutant == "sulfate") {
avg <- mean(dataset$sulfate, na.rm=TRUE)
}
else {
avg <- mean(dataset$nitrate, na.rm=TRUE)
}
round(avg,3)
}
pollutantmean("~/Courses/R-Programming/Data/specdata", "nitrate", 70:72)
pollutantmean <- function(directory, pollutant, id = 1:332) {
## 'directory' is a character vector of length 1 indicating
## the location of the CSV files
## 'pollutant' is a character vector of length 1 indicating
## the name of the pollutant for which we will calculate the
## mean; either "sulfate" or "nitrate".
## 'id' is an integer vector indicating the monitor ID numbers
## to be used
## Return the mean of the pollutant across all monitors list
## in the 'id' vector (ignoring NA values)
# find all files in directoy, subsetted by id
file_list <- list.files(directory, full.names=TRUE)[id ]
dataset = lapply(file_list, function(x){read.csv(file=x,header=T)})
Reduce(function(x,y) {merge(x,y)}, dataset)
dataset
## check which column to use for average, ignoring NA
#if (pollutant == "sulfate") {
#  avg <- mean(dataset$sulfate, na.rm=TRUE)
#}
#else {
#  avg <- mean(dataset$nitrate, na.rm=TRUE)
#}
#round(avg,3)
dataset
}
pollutantmean("~/Courses/R-Programming/Data/specdata", "nitrate", 70:72)
colnames(pollutantmean("~/Courses/R-Programming/Data/specdata", "nitrate", 70:72))
pollutantmean <- function(directory, pollutant, id = 1:332) {
## 'directory' is a character vector of length 1 indicating
## the location of the CSV files
## 'pollutant' is a character vector of length 1 indicating
## the name of the pollutant for which we will calculate the
## mean; either "sulfate" or "nitrate".
## 'id' is an integer vector indicating the monitor ID numbers
## to be used
## Return the mean of the pollutant across all monitors list
## in the 'id' vector (ignoring NA values)
# find all files in directoy, subsetted by id
file_list <- list.files(directory, full.names=TRUE)[id ]
dataset = lapply(file_list, function(x){read.csv(file=x)})
Reduce(function(x,y) {merge(x,y)}, dataset)
dataset
## check which column to use for average, ignoring NA
#if (pollutant == "sulfate") {
#  avg <- mean(dataset$sulfate, na.rm=TRUE)
#}
#else {
#  avg <- mean(dataset$nitrate, na.rm=TRUE)
#}
#round(avg,3)
dataset
}
colnames(pollutantmean("~/Courses/R-Programming/Data/specdata", "nitrate", 70:72))
pollutantmean <- function(directory, pollutant, id = 1:332) {
## 'directory' is a character vector of length 1 indicating
## the location of the CSV files
## 'pollutant' is a character vector of length 1 indicating
## the name of the pollutant for which we will calculate the
## mean; either "sulfate" or "nitrate".
## 'id' is an integer vector indicating the monitor ID numbers
## to be used
## Return the mean of the pollutant across all monitors list
## in the 'id' vector (ignoring NA values)
# find all files in directoy, subsetted by id
file_list <- list.files(directory, full.names=TRUE)[id ]
dataset = lapply(file_list, function(x){read.csv(file=x)})
data.names <- lapply(dataset, names)
Reduce(function(x,y) {merge(x,y)}, dataset)
colnames(dataset) <- data.names
## check which column to use for average, ignoring NA
#if (pollutant == "sulfate") {
#  avg <- mean(dataset$sulfate, na.rm=TRUE)
#}
#else {
#  avg <- mean(dataset$nitrate, na.rm=TRUE)
#}
#round(avg,3)
dataset
}
colnames(pollutantmean("~/Courses/R-Programming/Data/specdata", "nitrate", 70:72))
pollutantmean <- function(directory, pollutant, id = 1:332) {
## 'directory' is a character vector of length 1 indicating
## the location of the CSV files
## 'pollutant' is a character vector of length 1 indicating
## the name of the pollutant for which we will calculate the
## mean; either "sulfate" or "nitrate".
## 'id' is an integer vector indicating the monitor ID numbers
## to be used
## Return the mean of the pollutant across all monitors list
## in the 'id' vector (ignoring NA values)
# find all files in directoy, subsetted by id
file_list <- list.files(directory, full.names=TRUE)[id ]
dataset = lapply(file_list, function(x){read.csv(file=x)})
data.names <- colnames(dataset)
Reduce(function(x,y) {merge(x,y)}, dataset)
colnames(dataset) <- data.names
## check which column to use for average, ignoring NA
#if (pollutant == "sulfate") {
#  avg <- mean(dataset$sulfate, na.rm=TRUE)
#}
#else {
#  avg <- mean(dataset$nitrate, na.rm=TRUE)
#}
#round(avg,3)
dataset
}
colnames(pollutantmean("~/Courses/R-Programming/Data/specdata", "nitrate", 70:72))
pollutantmean <- function(directory, pollutant, id = 1:332) {
## 'directory' is a character vector of length 1 indicating
## the location of the CSV files
## 'pollutant' is a character vector of length 1 indicating
## the name of the pollutant for which we will calculate the
## mean; either "sulfate" or "nitrate".
## 'id' is an integer vector indicating the monitor ID numbers
## to be used
## Return the mean of the pollutant across all monitors list
## in the 'id' vector (ignoring NA values)
# find all files in directoy, subsetted by id
file_list <- list.files(directory, full.names=TRUE)[id ]
dataset = lapply(file_list, function(x){read.csv(file=x)})
data.names <- lapply(dataset,names)
Reduce(function(x,y) {merge(x,y)}, dataset)
colnames(dataset) <- data.names
## check which column to use for average, ignoring NA
#if (pollutant == "sulfate") {
#  avg <- mean(dataset$sulfate, na.rm=TRUE)
#}
#else {
#  avg <- mean(dataset$nitrate, na.rm=TRUE)
#}
#round(avg,3)
dataset
}
colnames(pollutantmean("~/Courses/R-Programming/Data/specdata", "nitrate", 70:72))
install.packages("missForest") #if needed for Impute outside randomForest
install.packages("MASS")       #for stepAIC
library(missForest)
library(ROCR)
library(MASS)
library(randomForest)
# set working directory
setwd("~/Courses/EdxAnalyticsEdge/Data")
# read in the train data & the test data
train = read.csv("train.csv")
test = read.csv("test.csv")
# inspect the data
str(train)
summary(train)
# inspect the test data
str(test)
summary(test)
library(rpart)
library(rpart.plot)
# install.packages("rpart.plot")
CARTmodel = rpart(Happy ~ ., data=train, method="class", control = rpart.control(cp = 0.002))
prp(CARTmodel)
plot(CARTmodel)
pred9 <- predict(CARTmodel, newdata=test,type="prob")
submission9 = data.frame(UserID = test$UserID, Probability1 = pred9[,2])
write.csv(submission9, "submission9.csv", row.names=FALSE)
pred9
?rpart
CARTmodel2 = rpart(Happy ~ ., data=train, method="class", control = rpart.control(cp = 0.002, xval=20, minsplit=60))
prp(CARTmodel2)
plot(CARTmodel2)
pred10 <- predict(CARTmodel2, newdata=test,type="prob")
submission10 = data.frame(UserID = test$UserID, Probability1 = pred10[,2])
write.csv(submission10, "submission11.csv", row.names=FALSE)
fit <- lm(Happy ~ ., data=train)
summary(fit)
pred = predict(fit, newdata=test, type="prop")
pred = predict(fit, newdata=test, type="response")
submission12 = data.frame(UserID = test$UserID, Probability1 = pred)
write.csv(submission12, "submission12.csv", row.names=FALSE)
fit <- lm(Happy ~ .-YOB , data=train)
summary(fit)
pred = predict(fit, newdata=test, type="response")
submission12 = data.frame(UserID = test$UserID, Probability1 = pred)
write.csv(submission12, "submission12.csv", row.names=FALSE)
fit <- lm(Happy ~ .-YOB-votes , data=train)
summary(fit)
pred = predict(fit, newdata=test, type="response")
submission12 = data.frame(UserID = test$UserID, Probability1 = pred)
write.csv(submission12, "submission12.csv", row.names=FALSE)
setwd("~/Courses/R-GettIngAndCleaningData/Data/UCI HAR Dataset")
lines = readlines("./train/X_train.txt")
lines = readLines("./train/X_train.txt")
lines[1]
strsplit(lines[1], split=" ")
strsplit(lines[1], split="  "," ")
strsplit(lines[1], split=" ")
lines[1]
?lapply
?read.fwf
train <- read.fwf("./train/X_train.txt",widths=16,sep="\n")
summary(train)
colnames(train) <- cnames
cnames <- read.table("./features.txt",sep=' ', stringsAsFactors=FALSE)[,2]
length(cnames)
str(cnames)
colnames(train) <- cnames
train
train <- read.fwf("./train/X_train.txt",widths=16)
train
?read.file
?read.File
?read.table
train <- read.fwf("./train/X_train.txt",widths=c(16))
train
lines <- readLines("./train/X_train.txt")
lines[1]
length("  2.8858451e-001")
str_length("  2.8858451e-001")
?read.fwf
install.packages("LaF") # for processing fixed width files
library(LaF)
cnames <- read.table("./features.txt",sep=' ', stringsAsFactors=FALSE)[,2]
length(cnames)
train <- laf_open_fwf(filename = "./train/X_train.txt",
column_types=c("double"),
column_names=cnames,
column_widths=c(16))
lines <- readLines("./train/X_train.txt")
nchar(lines[1])
8976/16
length(cnames)
train <- laf_open_fwf(filename = "./train/X_train.txt",
column_types=c("double"),
column_widths=c(16))
train
?laf_open_fwf
file <- laf_open_fwf(filename = "./train/X_train.txt",
column_types=c("double"),
column_widths=c(16))
train <- file[,]
train
nchar(lines[1])
file <- laf_open_fwf(filename = "./train/X_train.txt",
column_types=c("double"),
column_widths=c(16,16))
file <- laf_open_fwf(filename = "./train/X_train.txt",
column_widths=c(16,16))
file <- laf_open_fwf(filename = "./train/X_train.txt",
column_types=c("double","double"),
column_widths=c(16,16))
train <- file[,]
train
file <- laf_open_fwf(filename = "./train/X_train.txt",
column_types=c("double","double","double","double"),
column_widths=c(16,16,16,16))
train <- file[,]
train
columnCount <- length(cnames)
file <- laf_open_fwf(filename = "./train/X_train.txt",
column_types=rep("double", columnCount),
column_names=cnames,
column_widths=rep(16,columnCount))
train <- file[,]
summary(train)
str(cnames)
nchar(lines[1])
lineWidth <- nchar(readLines("./train/X_train.txt")[1])
lineWidth
columnWidth <- lineWidth / columnCount
columnWidth
file <- laf_open_fwf(filename = "./train/X_train.txt",
column_types=rep("double", columnCount),
column_names=cnames,
column_widths=rep(columnWidth,columnCount))
train <- file[,]
str(train)
file2 <- laf_open_fwf(filename = "./test/X_test.txt",
column_types=rep("double", columnCount),
column_names=cnames,
column_widths=rep(columnWidth,columnCount))
test <- file2[,]
?rbind
str(test)
data <- rbind(train,test)
trainrowCount <- nrow(train)
testrowCount <- nrow(test)
nrow(data)==trainrowCount+testrowCount
